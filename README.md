# Allocation Harms in LLMs

This project evaluates allocational harms in Large Language Models using the **RABBI** metric, as introduced in:

**The Mismeasure of Man and Models: Evaluating Allocational Harms in Large Language Models**  
[https://arxiv.org/pdf/2408.01285](https://arxiv.org/pdf/2408.01285)

---

## Overview

We benchmark the RABBI metric across **three datasets** and **two LLMs** to study how models distribute beneficial outcomes across groups.

---

## Datasets

1. **PISA (2022)**  
   <https://www.oecd.org/en/data/datasets/pisa-2022-database.html>

2. **COMPAS**  
   <https://www.kaggle.com/datasets/danofer/compass>

3. **DRESS**  
   <https://drive.google.com/drive/folders/1HQm5YDfZ-xDOgUAtMfCOvPBiESYCxOx3>

---

## Evaluated LLMs

1. **Llama-2-7b-chat-hf**
2. **StableLM-2-Zephyr-1.6B**

---
